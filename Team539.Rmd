---
title: "Presidential Election Maps for United Sates from 1920s"
author: "Team FiveThirtyNine"
date: "12/3/2017"
output: html_document
---
# Libraries Needed
```{r, message=F}
library(stringr)
library(dplyr)
library(tidyr)
library(shiny)
library(rvest)
library(ggplot2)
library(maps)
library(leaflet)
library(sf)
library(datamap)
library(rMaps)
devtools::install_github("hrbrmstr/albersusa")
library(albersusa)
```

```{r}
#here's an basic scrape for 1924 election
html_str <- "https://en.wikipedia.org/wiki/United_States_presidential_election,_1924#Results_by_state"
## web_url is the same, just replace 1924 for another yr for a different election ##

page <- read_html(html_str)
raw_table <- page %>% 
  html_nodes(xpath = '//*[@id="mw-content-text"]/div/table[15]') %>% html_table()
## Problem: the xpath is not constant across all years ##
## The selector for the tables doesn't appear to be consistent across pages either ##

raw_table <- raw_table[[1]]
View(raw_table)


#this, along with conditional statement in function, may have resolved the issue
xp <- c(10,15,8,7,7,9,6,11,7,8,6,6,12,7,6,7,14,8,7,15,24,16,24,22,39)
yr <- seq(1920,2016, by = 4)
xpath <- as.list(setNames(xp,yr))

  html_str <- paste0("https://en.wikipedia.org/wiki/United_States_presidential_election,_",year,"#Results_by_state")
  
  page <- read_html(html_str)
  
  if(year>=1996){
      raw_table <- page %>% 
        html_nodes(xpath = paste0('//*[@id="mw-content-text"]/div/div[',
                              xpath[[as.character(year)]],']/table')) %>% 
        html_table()
  }else{
    raw_table <- page %>% 
      html_nodes(xpath = paste0('//*[@id="mw-content-text"]/div/table[',
                              xpath[[as.character(year)]],']')) %>%
      html_table()
  }

  raw_table <- raw_table[[1]]
 
```

# Scraping Data from Wikipedia
```{r}
get_election_data=function(year){

  html_str<-paste0("https://en.wikipedia.org/wiki/United_States_presidential_election,_",year,"#Results_by_state")
 
  
  wiki<-read_html(html_str)
  wikitables<-wiki%>%html_nodes(".wikitable.sortable")
  
  for(i in 1:length(wikitables)){
    temp=wikitables[[i]]%>%html_table(fill=TRUE)
    if(nrow(temp)>49)
      {
        result_table=temp
        break
      }
  }
  
  if(year == 1992){
    colnames(result_table)<-paste(result_table[1,],result_table[2,]) %>%
      str_replace_all("\n"," ") %>%
      str_replace_all("^\\s","")
    result_table<-result_table[-c(1,2),]
  }
  else{
    colnames(result_table)<-paste(colnames(result_table),result_table[1,]) %>%
      str_replace_all("\n"," ") %>%
      str_replace_all("^\\s","")
    result_table<-result_table[-1,]
  }

  return(result_table)
}
# year=2016
#test<-get_election_data(year)

a<-get_election_data(2016)
b<-get_election_data(1992)
```

#Below and up functions are nearly the same, so pick the more simple one

```{r}
get_election_data=function(year){

  html_str<-paste0("https://en.wikipedia.org/wiki/United_States_presidential_election,_",year,"#Results_by_state")
   wiki<-read_html(html_str)
  wikitables<-wiki%>%html_nodes(".wikitable.sortable")
  
  for(i in 1:length(wikitables)){
    temp=wikitables[[i]]%>%html_table(fill=TRUE)
    if(nrow(temp)>49 &nrow(temp) < 60)
      {
        result_table=temp
        break
      }
  }
  
  if(year == 1992){
    result_table[1,]=str_replace_all(result_table[1,],"^.*(?<=\\))","Margin")
    result_table =  result_table %>%  `colnames<-`(paste( result_table[1,], result_table[2,])) %>%slice(-1:-2) 
      }else{
    result_table = result_table %>% `colnames<-`(paste0(colnames(result_table),result_table[1,])) %>% slice(-1)
    }
  return(result_table)
}
 
```

# Draw US map
```{r}
# way 1
mapStates<-map("state",fill=TRUE,plot=FALSE)
leaflet(data=mapStates)%>%addTiles()%>%addPolygons(fillColor = topo.colors(10,alpha=NULL),stroke = FALSE)

# way 2
all_states <- map_data("state")
ggplot()+
  geom_polygon(data=all_states, aes(x=long, y=lat, group=group),colour="white")

#using albersusa
usa <- usa_sf()
map <- leaflet(usa) %>% addPolygons() 

#using datamap
us_state_map <- Datamaps$new()
us_state_map$set(
  scope = 'usa',
  legend = TRUE,
  labels = TRUE
)

```


# Shiny App
```{r}
#perhaps we could take cosmetic elements from Mine's SuperZip app: 
#https://shiny.rstudio.com/gallery/superzip-example.html

shinyApp(
  ui = fluidPage(
        leafletOutput("map", width="100%",height=650),
        absolutePanel(id = "elec_dat",top = 50,
                   left = 20,right = "auto", bottom = "auto",
                   width = 300, height = "auto", draggable = TRUE, fixed = TRUE,
          wellPanel(
          h3("Presidential Election App"),
          numericInput("yearr","Year", min = 1920, max = 2016, step = 4, value = 1996),
          actionButton("do", "See Results"),
          style = "opacity: 0.75"
          )         
        )
  ),
  server = function(input, output, session) 
  {
    output$map <- renderLeaflet({
      leaflet(usa) %>% addPolygons()})
    
    }
  
)
```
